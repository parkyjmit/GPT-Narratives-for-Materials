{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yj/anaconda3/envs/clamp_p/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "name = \"m3rg-iitd/matscibert\"  # \"allenai/scibert_scivocab_cased\"\n",
    "df = pd.read_parquet('/mnt/hdd1/LaMDa/mp_3d_2020_gpt_narratives.parquet')\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126335it [1:28:19, 23.84it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "answer_list = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "        row['atoms'].pop('coords')\n",
    "        row['atoms'].pop('props')\n",
    "        prompt = 'Which of the following statements is most correct regarding the given material?' + str(row['atoms'])\n",
    "        inputs = tokenizer([[prompt, candidate] for candidate in row['structure_question_list']], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0).cuda()\n",
    "\n",
    "        outputs = model(**{k: v.unsqueeze(0).cuda() for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        answer_list.append(logits.argmax().item())\n",
    "    except:\n",
    "        answer_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081212648909645"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count -1 \n",
    "sum([i == 0 for i in answer_list])/len(answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126335it [2:16:33, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "comp_answer_list = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "        # row['atoms'].pop('coords')\n",
    "        # row['atoms'].pop('props')\n",
    "        prompt = 'Which of the following statements is most correct regarding the given material?' + str(row['atoms'])\n",
    "        inputs = tokenizer([[prompt, candidate] for candidate in row['composition_question_list']], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0).cuda()\n",
    "\n",
    "        outputs = model(**{k: v.unsqueeze(0).cuda() for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        comp_answer_list.append(logits.argmax().item())\n",
    "    except:\n",
    "        comp_answer_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015411406181976492, 11074)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i == 0 for i in comp_answer_list])/len(comp_answer_list), sum([i == -1 for i in comp_answer_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126335it [1:15:56, 27.72it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "oxide_answer_list = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "        # row['atoms'].pop('coords')\n",
    "        # row['atoms'].pop('props')\n",
    "        prompt = 'Which of the following statements is most correct regarding the given material?' + str(row['atoms'])\n",
    "        inputs = tokenizer([[prompt, candidate] for candidate in row['oxide_question_list']], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0).cuda()\n",
    "\n",
    "        outputs = model(**{k: v.unsqueeze(0).cuda() for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        oxide_answer_list.append(logits.argmax().item())\n",
    "    except:\n",
    "        oxide_answer_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00508964261685202, 7391)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i == 0 for i in oxide_answer_list])/len(oxide_answer_list), sum([i == -1 for i in oxide_answer_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126335it [1:27:11, 24.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "comp_struc_answer_list = []\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "        # row['atoms'].pop('coords')\n",
    "        # row['atoms'].pop('props')\n",
    "        prompt = 'Which of the following statements is most correct regarding the given material?' + str(row['atoms'])\n",
    "        inputs = tokenizer([[prompt, candidate] for candidate in row['comp_struc_question_list']], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0).cuda()\n",
    "\n",
    "        outputs = model(**{k: v.unsqueeze(0).cuda() for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        comp_struc_answer_list.append(logits.argmax().item())\n",
    "    except:\n",
    "        comp_struc_answer_list.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09204891756045434, 7938)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i == 0 for i in comp_struc_answer_list])/len(comp_struc_answer_list), sum([i == -1 for i in comp_struc_answer_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clamp_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
